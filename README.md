# MachineLearning

# Assignment 1

### 2.1 Polynomial Regression 

- **Objective:** Fit a non-linear function using polynomial regression on the feasible space X = [0, 11].

### 2.2 Linear Regression 

- **Objective:** Predict attributes 24 and 25 using attributes 3-23 through linear regression. Perform repeated trials for evaluation.

# Assignment 2

### 2.1 Logistic Regression Implementation: Gradient Descent

- **Objective:** Implement gradient descent for logistic regression, visualize the decision boundary, and submit the modified Jupyter notebook.

### 2.2 Support Vector Machines Implementations

#### Objective:

- **Implement SVMs with Different Kernels and Slack Variables:**
  - Train SVM classifiers for three distinct iris types using scikit-learn package.
  - Bonus Challenge: Implement SVM from scratch (12 points).
  - Conduct experiments with different SVM setups:
    - Calculate errors, weight vector, bias, support vector indices, and slack variables.
    - Explore linear kernel, varying slack variable C, and different kernel functions.

# Assignment 3

## 2.1 Tree

- **Objective:** Practice tree-based methods on the Diabetes dataset.
  
  - Preliminary data analysis with visualizations.
  - Data processing if necessary, with a data splitting ratio of 0.33.
  - Implement a uni-variate tree method for classification.
  - Implement an ensemble model for classification (free to choose).
  - Result visualizations, comments, and optional space-split visualization.
 
## 2.2 Neural Networks

- **Objective:** Build fully-connected Neural Network (MLP) and Convolutional Neural Network for digit classification on MNIST dataset.

# Assignment 4
- **Objectives**:
1. **Clustering:**
   - Implement K-means and GMMs.
2. **Metrics:**
   - Silhouette Coefficient, Rand Index, and NMI.
3. **Task 2.1:**
   - Implement algorithms and metrics.
4. **Task 2.2:**
   - Plot metrics for various k values.
   - Choose optimal k for each metric.
   - Calculate NMI for selected k.
